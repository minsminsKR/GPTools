import streamlit as st
from langchain_community.document_loaders import ( 
    PyPDFLoader, UnstructuredFileLoader, CSVLoader, UnstructuredExcelLoader 
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_community.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
import os
import tempfile
from langchain.chat_models import ChatOpenAI
from tools import *
from langchain.schema import Document  # Document ê°ì²´ ì¶”ê°€
import time  # ì‹¤ì‹œê°„ ë¬¸ì ì¶œë ¥ì— ì‚¬ìš©


# OpenAI API Key ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title('ğŸ¦œğŸ”—Welcome to GPTools ğŸ“œ')
    st.sidebar.success("ğŸ‘† Select a page above.")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        reset_chat()

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "Upload one or multiple files. Supported formats are **pdf, docx, doc, xlsx, xls, csv**, and **txt**. Your files won't be stored here.",
        accept_multiple_files=True
    )

    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ì„¸ì…˜ì„ ì´ˆê¸°í™”
    if not uploaded_files and st.session_state.get('file_uploaded', False):
        reset_chat()
        st.session_state.file_uploaded = False

    if uploaded_files:
        st.session_state.file_uploaded = True  # íŒŒì¼ ì—…ë¡œë“œ ìƒíƒœ ì €ì¥
        text = []
        for file in uploaded_files:
            file_extension = os.path.splitext(file.name)[1]
            with tempfile.NamedTemporaryFile(delete=False) as temp_file:
                temp_file.write(file.read())
                temp_file_path = temp_file.name

            loader = None

            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¡œë” ì„ íƒ
            if file_extension == ".pdf":
                loader = PyPDFLoader(temp_file_path)
            elif file_extension in [".docx", ".doc"]:
                loader = UnstructuredFileLoader(temp_file_path, file_type="docx")
            elif file_extension == ".csv":
                loader = CSVLoader(temp_file_path)
            elif file_extension in [".xlsx", ".xls"]:
                loader = UnstructuredExcelLoader(temp_file_path)
            elif file_extension == ".txt":
                try:
                    text_content = load_txt_file(temp_file_path)
                    text.append(text_content)
                except Exception as e:
                    st.error(f"Failed to load txt file: {e}")

            if loader:
                try:
                    loaded_documents = loader.load()
                    text.extend(doc.page_content for doc in loaded_documents)
                except Exception as e:
                    st.error(f"Failed to load file: {e}")

            os.remove(temp_file_path)

        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = [Document(page_content=txt) for txt in text]

        # í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        texts = text_splitter.split_documents(documents)

        # ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ì²˜ë¦¬
        persist_directory = tempfile.mkdtemp()  # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        embedding = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
        vectordb = Chroma.from_documents(
            documents=texts,
            embedding=embedding,
            persist_directory=persist_directory
        )

        # ë²¡í„° DB ì €ì¥
        vectordb.persist()
        vectordb = None

        # ë²¡í„° DB ì´ˆê¸°í™”
        vectordb = Chroma(
            persist_directory=persist_directory,
            embedding_function=embedding
        )

        retriever = vectordb.as_retriever()

        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
        for message in st.session_state.messages:
            if message['role'] == 'user':
                st.chat_message("user").markdown(message['content'])
            else:
                st.chat_message("assistant").markdown(message['content'])

        # ìœ ì €ì˜ ì§ˆë¬¸ ì…ë ¥
        user_input = st.chat_input("Ask anything about your files")

        if user_input:
            # ìœ ì € ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥
            st.session_state.messages.append({"role": "user", "content": user_input})
            st.chat_message("user").markdown(user_input)

            # GPT ì‘ë‹µ ì²˜ë¦¬
            qa_chain = RetrievalQA.from_chain_type(
                llm=ChatOpenAI(
                    model_name="gpt-4o-mini",
                    temperature=0,
                    openai_api_key=os.getenv("OPENAI_API_KEY")
                ),
                retriever=retriever,
                return_source_documents=True,
                chain_type="stuff"
            )
            result = qa_chain({"query": user_input})
            assistant_reply = result['result']

            # GPTì˜ ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

            # GPT ì‘ë‹µì„ í•œ ê¸€ìì”© ì¶œë ¥ (ì•„ì´ì½˜ê³¼ í•¨ê»˜)
            with st.chat_message("assistant"):
                message_container = st.empty()  # ë¹„ì–´ìˆëŠ” ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±
                display_typing_effect(message_container, assistant_reply)

# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == '__main__':
    main()