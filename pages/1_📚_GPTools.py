##########################################################
## ì„¸ì…˜ ê¸°ì–µ êµ¬í˜„í•˜ê¸° ##
##########################################################

import streamlit as st
from langchain_community.document_loaders import ( 
    PyPDFLoader, UnstructuredFileLoader, CSVLoader, UnstructuredExcelLoader 
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_community.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
import os
import tempfile
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import Document  # Document ê°ì²´ ì¶”ê°€
import chardet

# OpenAI API Key ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# openai.api_key = st.secrets["api_key"]

# ì‹¤ì‹œê°„ìœ¼ë¡œ ê¸€ì ì¶œë ¥í•˜ëŠ” í•¸ë“¤ëŸ¬
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title('ğŸ¦œğŸ”—Welcome to GPTools ğŸ“œ')
    st.sidebar.success("ğŸ‘† Select a page above.")

    uploaded_files = st.file_uploader(
        "Upload one or multiple files. Supported formats are **pdf, docx, doc**, **csv**, and **txt**.",
        accept_multiple_files=True
    )

    if uploaded_files:
        text = []
        for file in uploaded_files:
            file_extension = os.path.splitext(file.name)[1]
            with tempfile.NamedTemporaryFile(delete=False) as temp_file:
                temp_file.write(file.read())
                temp_file_path = temp_file.name

            loader = None

            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¡œë” ì„ íƒ
            if file_extension == ".pdf":
                loader = PyPDFLoader(temp_file_path)
                
#####################################################################################
# pdf ì´ë¯¸ì§€, í…Œì´ë¸” ë“±ë“± ocr ê°™ì€ê±° í•„ìš”í•¨.
#####################################################################################
                
                
            elif file_extension in [".docx", ".doc"]:
                loader = UnstructuredFileLoader(temp_file_path, file_type="docx")
            elif file_extension == ".csv":
                loader = CSVLoader(temp_file_path)
            elif file_extension in [".xlsx", ".xls"]:
                loader = UnstructuredExcelLoader(temp_file_path)
            elif file_extension == ".txt":
                # í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì¸ì½”ë”© ìë™ ê°ì§€ í›„ ì½ê¸°
                with open(temp_file_path, 'rb') as f:
                    raw_data = f.read()
                    encoding = chardet.detect(raw_data)['encoding']

                # ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸°
                try:
                    with open(temp_file_path, 'r', encoding=encoding) as f:
                        text.append(f.read())
                except Exception as e:
                    st.error(f"Failed to load txt file: {e}")

            if loader:
                try:
                    loaded_documents = loader.load()
                    # ê° ë¬¸ì„œì˜ page_contentë¥¼ text ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    text.extend(doc.page_content for doc in loaded_documents)
                except Exception as e:
                    st.error(f"Failed to load file: {e}")

            os.remove(temp_file_path)

        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = [Document(page_content=txt) for txt in text]

        # í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        texts = text_splitter.split_documents(documents)

        # ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ì²˜ë¦¬
        with st.spinner("Processing"):
            persist_directory = tempfile.mkdtemp()  # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            embedding = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
            vectordb = Chroma.from_documents(
                documents=texts,
                embedding=embedding,
                persist_directory=persist_directory
            )

        # ë²¡í„° DB ì €ì¥
        vectordb.persist()
        vectordb = None

        # ë²¡í„° DB ì´ˆê¸°í™”
        vectordb = Chroma(
            persist_directory=persist_directory,
            embedding_function=embedding
        )

        retriever = vectordb.as_retriever()

        # ì§ˆë¬¸ í¼ ìƒì„±
        with st.form("form", clear_on_submit=True):
            st.header("Chat with GPT ğŸ˜„")
            question = st.text_input("Ask anything about your files", placeholder="Enter to submit")
            submit = st.form_submit_button("Submit")

            if submit and question:
                with st.spinner("Wait for it..."):
                    chat_box = st.empty()
                    stream_handler = StreamHandler(chat_box)
                    qa_chain = RetrievalQA.from_chain_type(
                        llm=ChatOpenAI(
                            model_name="gpt-4o-mini",
                            temperature=0,
                            streaming=True,
                            callbacks=[stream_handler],
                            openai_api_key=os.getenv("OPENAI_API_KEY") # # openai.api_key = st.secrets["api_key"]
                        ),
                        retriever=retriever,
                        return_source_documents=True,
                        chain_type="stuff"
                    )
                    qa_chain({"query": question})

# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == '__main__':
    main()